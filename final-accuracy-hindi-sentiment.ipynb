{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63119a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdbc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output/shuffled_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11210286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8977afcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>913</td>\n",
       "      <td>positive</td>\n",
       "      <td>क्या यही सच है आत्मकथात्मक फिल्मों की कड़ी में...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303</td>\n",
       "      <td>neutral</td>\n",
       "      <td>पद्मिनी कोल्हापुरे गायब हो चुकी रोती-बिसूरती म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900</td>\n",
       "      <td>positive</td>\n",
       "      <td>कलाकारों में नवोदित अभिनेता विपिन्नो का कार्य ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223</td>\n",
       "      <td>positive</td>\n",
       "      <td>इस फिल्म में सनी लियोनी ने अपने किरदार के साथ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1712</td>\n",
       "      <td>neutral</td>\n",
       "      <td>लाउड कामेडी के अभिनेताओं और उनका दुरुपयोग कर र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1970</td>\n",
       "      <td>neutral</td>\n",
       "      <td>फिल्म पूरी तरह उनके कंधों पर टिकी है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>596</td>\n",
       "      <td>conflict</td>\n",
       "      <td>लिएंडर पेस फिल्म के लीड स्टारकास्ट है लेकिन हॉ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>587</td>\n",
       "      <td>positive</td>\n",
       "      <td>वे सुंदर दिखी हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1542</td>\n",
       "      <td>conflict</td>\n",
       "      <td>आलाप में गंभीर राजनीतिक समस्या के काल्पनिक निद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>774</td>\n",
       "      <td>negative</td>\n",
       "      <td>फिल्म मनोरंजक भी नहीं लगती।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  polarity                                               text\n",
       "0    913  positive  क्या यही सच है आत्मकथात्मक फिल्मों की कड़ी में...\n",
       "1   1303   neutral  पद्मिनी कोल्हापुरे गायब हो चुकी रोती-बिसूरती म...\n",
       "2    900  positive  कलाकारों में नवोदित अभिनेता विपिन्नो का कार्य ...\n",
       "3   1223  positive  इस फिल्म में सनी लियोनी ने अपने किरदार के साथ ...\n",
       "4   1712   neutral  लाउड कामेडी के अभिनेताओं और उनका दुरुपयोग कर र...\n",
       "..   ...       ...                                                ...\n",
       "95  1970   neutral              फिल्म पूरी तरह उनके कंधों पर टिकी है।\n",
       "96   596  conflict  लिएंडर पेस फिल्म के लीड स्टारकास्ट है लेकिन हॉ...\n",
       "97   587  positive                                 वे सुंदर दिखी हैं।\n",
       "98  1542  conflict  आलाप में गंभीर राजनीतिक समस्या के काल्पनिक निद...\n",
       "99   774  negative                        फिल्म मनोरंजक भी नहीं लगती।\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c36717dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25\n",
       "neutral     25\n",
       "conflict    25\n",
       "negative    25\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c16424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']\n",
    "\n",
    "prompts = []\n",
    "\n",
    "for idx in range(0, len(text), 5):\n",
    "    prompts.append(f\"\"\"You are a text classification model. You have to classify data for a multiclass sentiment analysis task for Hindi. \n",
    "The sentence can be classified into 4 different categories namely: conflict, negative, neutral, positive. \n",
    "\n",
    "I'll give 2 examples of each of the category, and then pass 5 sentences. You'll need to classify the sentences into one of the above mentioned labels.\n",
    "\n",
    "conflict: करण ने चरित्र और स्थितियां तो रची हैं, पर सटीक चित्रण में कमी सी रह गई है।\n",
    "conflict: कहीं कम हंसी आती है तो कहीं ज्यादा हंसी आती है।\n",
    "negative: संजय दत्त अपने पॉपुलर  व्यक्तित्व के बावजूद इस फिल्म के लचर लेखन से किसी भी दृश्य में प्रभावित नहीं कर पाते।\n",
    "negative: फिल्म के नायक सूरज के मामा के अलावा किसी में भी अच्छाई नजर नहीं आती।\n",
    "neutral: वे स्थानीय स्तुर पर ‘हम किसी से कम नहीं’ कंपीटिशन में हिस्सा लेते हैं।\n",
    "neutral: नए जमाने की बेफिक्र लड़की, जिसकी जिंदगी में इमोशनल उतार-चढ़ाव फेसबुक के लाइक और कमेंट से प्रभावित होता है।\n",
    "positive: फिल्म के कुछ लक्षण उल्लेखनीय हैं।\n",
    "positive: गर पूरी फिल्म 3 डी होती तो यह रोमांच स्थायी और गहरा होता।\n",
    "\n",
    "Classify following sentences.\n",
    "\n",
    "{idx}. {text[idx]}\n",
    "{idx+1}. {text[idx+1]}\n",
    "{idx+2}. {text[idx+2]}\n",
    "{idx+3}. {text[idx+3]}\n",
    "{idx+4}. {text[idx+4]}\n",
    "\"\"\")\n",
    "    \n",
    "promptsDf = pd.DataFrame()\n",
    "promptsDf['prompt'] = prompts\n",
    "\n",
    "promptsDf.to_csv('prompts/final-output-prompts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7eac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "with open(f'prompts/curr-prompt.txt', 'w+') as f:\n",
    "    f.write(f'{prompts[idx]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f5cd622",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']\n",
    "\n",
    "promptsGuided = []\n",
    "\n",
    "for idx in range(0, len(text), 5):\n",
    "    promptsGuided.append(f\"\"\"You are a text classification model. You have to classify data for a multiclass sentiment analysis task for Hindi. \n",
    "The sentence can be classified into 4 different categories namely: conflict, negative, neutral, positive. \n",
    "\n",
    "I'll give 2 examples of each of the category, and then pass 5 sentences. You'll need to classify the sentences into one of the above mentioned labels.\n",
    "\n",
    "conflict: करण ने चरित्र और स्थितियां तो रची हैं, पर सटीक चित्रण में कमी सी रह गई है।\n",
    "conflict: कहीं कम हंसी आती है तो कहीं ज्यादा हंसी आती है।\n",
    "negative: संजय दत्त अपने पॉपुलर  व्यक्तित्व के बावजूद इस फिल्म के लचर लेखन से किसी भी दृश्य में प्रभावित नहीं कर पाते।\n",
    "negative: फिल्म के नायक सूरज के मामा के अलावा किसी में भी अच्छाई नजर नहीं आती।\n",
    "neutral: वे स्थानीय स्तुर पर ‘हम किसी से कम नहीं’ कंपीटिशन में हिस्सा लेते हैं।\n",
    "neutral: नए जमाने की बेफिक्र लड़की, जिसकी जिंदगी में इमोशनल उतार-चढ़ाव फेसबुक के लाइक और कमेंट से प्रभावित होता है।\n",
    "positive: फिल्म के कुछ लक्षण उल्लेखनीय हैं।\n",
    "positive: गर पूरी फिल्म 3 डी होती तो यह रोमांच स्थायी और गहरा होता।\n",
    "\n",
    "Classify following sentences.\n",
    "\n",
    "{idx}. {text[idx]}\n",
    "{idx+1}. {text[idx+1]}\n",
    "{idx+2}. {text[idx+2]}\n",
    "{idx+3}. {text[idx+3]}\n",
    "{idx+4}. {text[idx+4]}\n",
    "\n",
    "Output should be of the format:\n",
    "{idx}. label (conflict, negative, neutral, positive)\n",
    "{idx+1}. label (conflict, negative, neutral, positive)\n",
    "{idx+2}. label (conflict, negative, neutral, positive)\n",
    "{idx+3}. label (conflict, negative, neutral, positive)\n",
    "{idx+4}. label (conflict, negative, neutral, positive)\n",
    "\n",
    "Don't give any explanation, just the output in the format as said.\n",
    "\"\"\")\n",
    "    \n",
    "promptsDf = pd.DataFrame()\n",
    "promptsDf['prompt'] = promptsGuided\n",
    "\n",
    "promptsDf.to_csv('prompts/final-guided-output-prompts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "685d6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 19\n",
    "with open(f'prompts/curr-prompt.txt', 'w+') as f:\n",
    "    f.write(f'{prompts[idx]}\\n')\n",
    "with open(f'prompts/curr-guided-prompt.txt', 'w+') as f:\n",
    "    f.write(f'{promptsGuided[idx]}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ff37f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccbff56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = list(df['polarity'])\n",
    "polarity = [s.lower() for s in polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c64c1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessFunc(lines):\n",
    "    return [s.lower() for s in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bab372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "polarity = le.fit_transform(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb91bff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 3, 3, 2, 3, 0, 3, 2, 1, 1, 1, 0, 1, 3, 3, 3, 2, 1, 0, 2, 2,\n",
       "       2, 2, 2, 2, 3, 0, 1, 2, 3, 3, 1, 3, 0, 2, 1, 1, 1, 0, 3, 3, 1, 0,\n",
       "       3, 2, 3, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 3, 0, 0, 2,\n",
       "       1, 1, 3, 2, 0, 1, 0, 3, 2, 0, 0, 3, 2, 1, 2, 1, 0, 0, 1, 3, 3, 0,\n",
       "       3, 1, 1, 2, 0, 3, 1, 2, 0, 3, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0447667",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d22263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ekdnam/Documents/SP23/CSE291/project/hindi/sentiment-analysis\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c5d644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(filePath, preprocessFunc = None):\n",
    "    preds = []\n",
    "    with open(filePath) as file:\n",
    "        for line in file: \n",
    "            line = line.strip() #or some other preprocessing\n",
    "            preds.append(line) #storing everything in memory!\n",
    "            \n",
    "    if preprocessFunc is not None:\n",
    "        preds = preprocessFunc(preds)\n",
    "    \n",
    "    assert len(set(truth)) == len(set(preds))\n",
    "    \n",
    "    preds = le.transform(preds)\n",
    "    \n",
    "#     print(truth)\n",
    "#     print(preds)\n",
    "#     report = classification_report(truth, preds)\n",
    "    calculate_metrics(truth, preds)\n",
    "    \n",
    "#     return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7748ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    accuracy = accuracy_score(actual, predicted)\n",
    "    precision = precision_score(actual, predicted, average='macro')\n",
    "    recall = recall_score(actual, predicted, average='macro')\n",
    "    f1_macro = f1_score(actual, predicted, average='macro')\n",
    "    f1_micro = f1_score(actual, predicted, average='micro')\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"f1_macro: \", f1_macro)\n",
    "    print(\"f1_micro: \", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "759d1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE: chatgpt\n",
      "Accuracy:  0.45\n",
      "Precision:  0.4603402445507708\n",
      "Recall:  0.45\n",
      "f1_macro:  0.4464514835605453\n",
      "f1_micro:  0.45\n",
      "None\n",
      "TYPE: chatsonic\n",
      "Accuracy:  0.47\n",
      "Precision:  0.4628623188405797\n",
      "Recall:  0.47\n",
      "f1_macro:  0.4647080940661744\n",
      "f1_micro:  0.47\n",
      "None\n",
      "TYPE: huggingchat\n",
      "Accuracy:  0.22\n",
      "Precision:  0.2287595982448924\n",
      "Recall:  0.21999999999999997\n",
      "f1_macro:  0.22109188502987404\n",
      "f1_micro:  0.22\n",
      "None\n",
      "TYPE: perplexity\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fi \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTYPE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     report \u001b[38;5;241m=\u001b[39m generate_report(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal-2/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(report)\n",
      "Cell \u001b[0;32mIn [22], line 11\u001b[0m, in \u001b[0;36mgenerate_report\u001b[0;34m(filePath, preprocessFunc)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessFunc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         preds \u001b[38;5;241m=\u001b[39m preprocessFunc(preds)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(truth)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(preds))\n\u001b[1;32m     13\u001b[0m     preds \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(preds)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     print(truth)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     print(preds)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     report = classification_report(truth, preds)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = ['chatgpt', 'chatsonic', 'huggingchat', 'perplexity']\n",
    "\n",
    "for fi in files:\n",
    "    print(f\"TYPE: {fi}\")\n",
    "    report = generate_report(f'final-2/{fi}.txt', None)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57b0511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessFunc(lines):\n",
    "    return [l.strip().lower() for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92fba461",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with open(f'final-2/perplexity.txt') as file:\n",
    "    for line in file: \n",
    "        line = line.strip() #or some other preprocessing\n",
    "        preds.append(line) #storing everything in memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b329481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preprocessFunc(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ff6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(truth)) == len(set(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e49c637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.45\n",
      "Precision:  0.436489898989899\n",
      "Recall:  0.45000000000000007\n",
      "f1_macro:  0.4330431166322342\n",
      "f1_micro:  0.45\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(truth, le.transform(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82666469",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "fi = 'chatgpt'\n",
    "with open(f'final-2/{fi}.txt') as file:\n",
    "    for line in file: \n",
    "        line = line.strip() #or some other preprocessing\n",
    "        preds.append(line) #storing everything in memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcd8d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebf7dc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conflict', 'negative', 'neutral', 'positive'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c3309df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conflict', 'negative', 'neutral', 'positive'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(df['polarity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "226a576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = le.transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc0c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
